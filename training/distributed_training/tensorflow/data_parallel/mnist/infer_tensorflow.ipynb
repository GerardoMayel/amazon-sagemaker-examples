{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "false-concrete",
   "metadata": {
    "papermill": {
     "duration": 0.004401,
     "end_time": "2021-05-26T15:39:12.163646",
     "exception": false,
     "start_time": "2021-05-26T15:39:12.159245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 2: Deploy a model trained using SageMaker distributed data parallel\n",
    "\n",
    "To deploy the model you previously trained, you need to create a Sagemaker Endpoint. This is a hosted prediction service that you can use to perform inference.\n",
    "\n",
    "## Finding the model\n",
    "\n",
    "This notebook uses a stored model if it exists. If you recently ran a training example that use the `%store%` magic, it will be restored in the next cell.\n",
    "\n",
    "Otherwise, the notebook downloads a trained model artifact from a public bucket and uploads into your default S3 bucket for the AWS Region you use to run this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aging-equation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:39:12.177472Z",
     "iopub.status.busy": "2021-05-26T15:39:12.177022Z",
     "iopub.status.idle": "2021-05-26T15:39:12.603770Z",
     "shell.execute_reply": "2021-05-26T15:39:12.603341Z"
    },
    "papermill": {
     "duration": 0.43588,
     "end_time": "2021-05-26T15:39:12.603882",
     "exception": false,
     "start_time": "2021-05-26T15:39:12.168002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "def copy_model_from_public_bucket():\n",
    "    \"\"\"Copy a trained model artifact to your def\"\"\"\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    public_bucket = \"sagemaker-sample-files\"\n",
    "    key = \"datasets/image/MNIST/model/model.tar.gz\"\n",
    "    with open(os.path.join(\"/tmp\", \"model.tar.gz\"), \"wb\") as f:\n",
    "        s3.download_fileobj(public_bucket, key, f)\n",
    "\n",
    "    # upload to your default bucket\n",
    "    default_bucket = sagemaker.Session().default_bucket()\n",
    "    with open(os.path.join(\"/tmp\", \"model.tar.gz\"), \"rb\") as f:\n",
    "        s3.upload_fileobj(f, default_bucket, key)\n",
    "    return \"s3://\" + default_bucket + \"/\" + key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "destroyed-certification",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:39:12.625617Z",
     "iopub.status.busy": "2021-05-26T15:39:12.617379Z",
     "iopub.status.idle": "2021-05-26T15:39:13.923227Z",
     "shell.execute_reply": "2021-05-26T15:39:13.923615Z"
    },
    "papermill": {
     "duration": 1.315186,
     "end_time": "2021-05-26T15:39:13.923760",
     "exception": false,
     "start_time": "2021-05-26T15:39:12.608574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using this model: s3://sagemaker-us-west-2-688520471316/datasets/image/MNIST/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve a saved model from a previous notebook run's stored variable\n",
    "%store -r model_data\n",
    "\n",
    "try:\n",
    "    model_data\n",
    "except NameError:\n",
    "    # If no model was found, set it manually here.\n",
    "    model_data = copy_model_from_public_bucket()\n",
    "\n",
    "print(\"Using this model: {}\".format(model_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "advance-nurse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-688520471316/datasets/image/MNIST/model/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-us-west-2-688520471316/datasets/image/MNIST/model/model.tar.gz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deadly-platinum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Removing leading `/' from member names\n"
     ]
    }
   ],
   "source": [
    "!tar -xf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-energy",
   "metadata": {
    "papermill": {
     "duration": 0.00508,
     "end_time": "2021-05-26T15:39:13.934311",
     "exception": false,
     "start_time": "2021-05-26T15:39:13.929231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create a model object\n",
    "\n",
    "You define the model object by using SageMaker SDK's `TensorFlowModel` and pass in the model from the `estimator` and the `entry_point`. The function loads the model and sets it to use a GPU, if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handmade-paraguay",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:39:13.953599Z",
     "iopub.status.busy": "2021-05-26T15:39:13.953142Z",
     "iopub.status.idle": "2021-05-26T15:39:14.310967Z",
     "shell.execute_reply": "2021-05-26T15:39:14.311340Z"
    },
    "papermill": {
     "duration": 0.372132,
     "end_time": "2021-05-26T15:39:14.311507",
     "exception": false,
     "start_time": "2021-05-26T15:39:13.939375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "model = TensorFlowModel(model_data=model_data, role=role, framework_version=\"2.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-gates",
   "metadata": {
    "papermill": {
     "duration": 0.005164,
     "end_time": "2021-05-26T15:39:14.321933",
     "exception": false,
     "start_time": "2021-05-26T15:39:14.316769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Deploy the model on an endpoint\n",
    "\n",
    "You create a `predictor` by using the `model.deploy` function. You can optionally change both the instance count and instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indonesian-harvard",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:39:14.335425Z",
     "iopub.status.busy": "2021-05-26T15:39:14.334977Z",
     "iopub.status.idle": "2021-05-26T15:56:48.975112Z",
     "shell.execute_reply": "2021-05-26T15:56:48.974292Z"
    },
    "papermill": {
     "duration": 1054.648348,
     "end_time": "2021-05-26T15:56:48.975319",
     "exception": true,
     "start_time": "2021-05-26T15:39:14.326971",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint tensorflow-inference-2021-05-28-21-18-37-294: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f85ab568442b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ml.m4.xlarge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sagemaker/tensorflow/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, update_endpoint)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         )\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m             \u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m         )\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   3477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3479\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   2980\u001b[0m         )\n\u001b[1;32m   2981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_endpoint\u001b[0;34m(self, endpoint, poll)\u001b[0m\n\u001b[1;32m   3266\u001b[0m                 ),\n\u001b[1;32m   3267\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"InService\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3268\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3269\u001b[0m             )\n\u001b[1;32m   3270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint tensorflow-inference-2021-05-28-21-18-37-294: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.."
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suspended-reducing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow-inference-2021-05-28-21-18-37-294'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-grain",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "If you don't intend to try out inference or to do anything else with the endpoint, you should delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-carolina",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1058.142161,
   "end_time": "2021-05-26T15:56:49.481922",
   "environment_variables": {},
   "exception": true,
   "input_path": "infer_tensorflow.ipynb",
   "output_path": "/opt/ml/processing/output/infer_tensorflow-2021-05-26-15-35-27.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-05-26T15:39:11.339761",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
